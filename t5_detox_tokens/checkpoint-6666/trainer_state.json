{
  "best_global_step": 3333,
  "best_metric": 0.7583545446395874,
  "best_model_checkpoint": "./t5_detox_tokens\\checkpoint-3333",
  "epoch": 6.0,
  "eval_steps": 500,
  "global_step": 6666,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.045004500450045004,
      "grad_norm": 2.754936933517456,
      "learning_rate": 0.0002993654365436543,
      "loss": 1.3786,
      "step": 50
    },
    {
      "epoch": 0.09000900090009001,
      "grad_norm": 1.6336047649383545,
      "learning_rate": 0.00029869036903690363,
      "loss": 1.0775,
      "step": 100
    },
    {
      "epoch": 0.135013501350135,
      "grad_norm": 1.985870122909546,
      "learning_rate": 0.000298015301530153,
      "loss": 1.0582,
      "step": 150
    },
    {
      "epoch": 0.18001800180018002,
      "grad_norm": 3.052374839782715,
      "learning_rate": 0.0002973402340234023,
      "loss": 1.014,
      "step": 200
    },
    {
      "epoch": 0.22502250225022502,
      "grad_norm": 2.006831645965576,
      "learning_rate": 0.00029666516651665164,
      "loss": 0.9478,
      "step": 250
    },
    {
      "epoch": 0.27002700270027,
      "grad_norm": 1.288743495941162,
      "learning_rate": 0.00029599009900990096,
      "loss": 1.0202,
      "step": 300
    },
    {
      "epoch": 0.31503150315031503,
      "grad_norm": 2.0298469066619873,
      "learning_rate": 0.0002953150315031503,
      "loss": 0.9458,
      "step": 350
    },
    {
      "epoch": 0.36003600360036003,
      "grad_norm": 2.270159959793091,
      "learning_rate": 0.00029463996399639966,
      "loss": 0.9983,
      "step": 400
    },
    {
      "epoch": 0.40504050405040504,
      "grad_norm": 1.9782639741897583,
      "learning_rate": 0.000293964896489649,
      "loss": 0.9609,
      "step": 450
    },
    {
      "epoch": 0.45004500450045004,
      "grad_norm": 1.4025485515594482,
      "learning_rate": 0.0002932898289828983,
      "loss": 0.9662,
      "step": 500
    },
    {
      "epoch": 0.49504950495049505,
      "grad_norm": 2.6168437004089355,
      "learning_rate": 0.00029261476147614756,
      "loss": 0.9448,
      "step": 550
    },
    {
      "epoch": 0.54005400540054,
      "grad_norm": 1.9741333723068237,
      "learning_rate": 0.0002919396939693969,
      "loss": 0.947,
      "step": 600
    },
    {
      "epoch": 0.585058505850585,
      "grad_norm": 1.6052510738372803,
      "learning_rate": 0.00029126462646264625,
      "loss": 0.8686,
      "step": 650
    },
    {
      "epoch": 0.6300630063006301,
      "grad_norm": 1.6453756093978882,
      "learning_rate": 0.00029058955895589557,
      "loss": 0.9513,
      "step": 700
    },
    {
      "epoch": 0.6750675067506751,
      "grad_norm": 1.1573933362960815,
      "learning_rate": 0.0002899144914491449,
      "loss": 0.957,
      "step": 750
    },
    {
      "epoch": 0.7200720072007201,
      "grad_norm": 1.4224969148635864,
      "learning_rate": 0.0002892394239423942,
      "loss": 0.924,
      "step": 800
    },
    {
      "epoch": 0.7650765076507651,
      "grad_norm": 1.344914197921753,
      "learning_rate": 0.00028856435643564353,
      "loss": 0.9158,
      "step": 850
    },
    {
      "epoch": 0.8100810081008101,
      "grad_norm": 1.852933645248413,
      "learning_rate": 0.0002878892889288929,
      "loss": 0.9261,
      "step": 900
    },
    {
      "epoch": 0.8550855085508551,
      "grad_norm": 1.8080273866653442,
      "learning_rate": 0.0002872142214221422,
      "loss": 0.863,
      "step": 950
    },
    {
      "epoch": 0.9000900090009001,
      "grad_norm": 2.4637603759765625,
      "learning_rate": 0.00028653915391539154,
      "loss": 0.9115,
      "step": 1000
    },
    {
      "epoch": 0.9450945094509451,
      "grad_norm": 1.9331109523773193,
      "learning_rate": 0.00028586408640864086,
      "loss": 0.9196,
      "step": 1050
    },
    {
      "epoch": 0.9900990099009901,
      "grad_norm": 1.6669822931289673,
      "learning_rate": 0.00028518901890189013,
      "loss": 0.8846,
      "step": 1100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.7816904783248901,
      "eval_runtime": 18.9872,
      "eval_samples_per_second": 104.017,
      "eval_steps_per_second": 13.009,
      "step": 1111
    },
    {
      "epoch": 1.035103510351035,
      "grad_norm": 1.6412675380706787,
      "learning_rate": 0.0002845274527452745,
      "loss": 0.8033,
      "step": 1150
    },
    {
      "epoch": 1.08010801080108,
      "grad_norm": 1.478088617324829,
      "learning_rate": 0.0002838523852385238,
      "loss": 0.8079,
      "step": 1200
    },
    {
      "epoch": 1.125112511251125,
      "grad_norm": 1.7231658697128296,
      "learning_rate": 0.00028317731773177315,
      "loss": 0.8222,
      "step": 1250
    },
    {
      "epoch": 1.17011701170117,
      "grad_norm": 1.1270108222961426,
      "learning_rate": 0.00028250225022502246,
      "loss": 0.8319,
      "step": 1300
    },
    {
      "epoch": 1.215121512151215,
      "grad_norm": 0.9814227819442749,
      "learning_rate": 0.0002818271827182718,
      "loss": 0.8057,
      "step": 1350
    },
    {
      "epoch": 1.2601260126012601,
      "grad_norm": 1.4280585050582886,
      "learning_rate": 0.0002811521152115211,
      "loss": 0.804,
      "step": 1400
    },
    {
      "epoch": 1.3051305130513051,
      "grad_norm": 0.897290050983429,
      "learning_rate": 0.0002804770477047704,
      "loss": 0.8009,
      "step": 1450
    },
    {
      "epoch": 1.3501350135013501,
      "grad_norm": 1.4693372249603271,
      "learning_rate": 0.0002798019801980198,
      "loss": 0.809,
      "step": 1500
    },
    {
      "epoch": 1.3951395139513951,
      "grad_norm": 2.4739720821380615,
      "learning_rate": 0.0002791269126912691,
      "loss": 0.8054,
      "step": 1550
    },
    {
      "epoch": 1.4401440144014401,
      "grad_norm": 1.7039060592651367,
      "learning_rate": 0.00027845184518451844,
      "loss": 0.8144,
      "step": 1600
    },
    {
      "epoch": 1.4851485148514851,
      "grad_norm": 1.3295730352401733,
      "learning_rate": 0.00027777677767776776,
      "loss": 0.7728,
      "step": 1650
    },
    {
      "epoch": 1.5301530153015301,
      "grad_norm": 1.5695935487747192,
      "learning_rate": 0.0002771017101710171,
      "loss": 0.802,
      "step": 1700
    },
    {
      "epoch": 1.5751575157515751,
      "grad_norm": 1.2811437845230103,
      "learning_rate": 0.0002764266426642664,
      "loss": 0.8368,
      "step": 1750
    },
    {
      "epoch": 1.6201620162016201,
      "grad_norm": 1.4027787446975708,
      "learning_rate": 0.0002757515751575157,
      "loss": 0.7943,
      "step": 1800
    },
    {
      "epoch": 1.6651665166516652,
      "grad_norm": 1.3471630811691284,
      "learning_rate": 0.00027507650765076503,
      "loss": 0.7566,
      "step": 1850
    },
    {
      "epoch": 1.7101710171017102,
      "grad_norm": 1.4606560468673706,
      "learning_rate": 0.00027440144014401435,
      "loss": 0.7601,
      "step": 1900
    },
    {
      "epoch": 1.7551755175517552,
      "grad_norm": 1.5656139850616455,
      "learning_rate": 0.00027372637263726367,
      "loss": 0.7609,
      "step": 1950
    },
    {
      "epoch": 1.8001800180018002,
      "grad_norm": 1.7367260456085205,
      "learning_rate": 0.00027305130513051305,
      "loss": 0.7707,
      "step": 2000
    },
    {
      "epoch": 1.8451845184518452,
      "grad_norm": 1.442245364189148,
      "learning_rate": 0.00027237623762376236,
      "loss": 0.7813,
      "step": 2050
    },
    {
      "epoch": 1.8901890189018902,
      "grad_norm": 1.8864636421203613,
      "learning_rate": 0.0002717011701170117,
      "loss": 0.7915,
      "step": 2100
    },
    {
      "epoch": 1.9351935193519352,
      "grad_norm": 2.085561752319336,
      "learning_rate": 0.000271026102610261,
      "loss": 0.7736,
      "step": 2150
    },
    {
      "epoch": 1.9801980198019802,
      "grad_norm": 1.1202114820480347,
      "learning_rate": 0.0002703510351035103,
      "loss": 0.7598,
      "step": 2200
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7585878968238831,
      "eval_runtime": 20.3654,
      "eval_samples_per_second": 96.978,
      "eval_steps_per_second": 12.128,
      "step": 2222
    },
    {
      "epoch": 2.025202520252025,
      "grad_norm": 1.1294751167297363,
      "learning_rate": 0.00026967596759675964,
      "loss": 0.7364,
      "step": 2250
    },
    {
      "epoch": 2.07020702070207,
      "grad_norm": 1.6201260089874268,
      "learning_rate": 0.00026900090009000896,
      "loss": 0.7548,
      "step": 2300
    },
    {
      "epoch": 2.115211521152115,
      "grad_norm": 1.6514023542404175,
      "learning_rate": 0.0002683258325832583,
      "loss": 0.6843,
      "step": 2350
    },
    {
      "epoch": 2.16021602160216,
      "grad_norm": 1.3110491037368774,
      "learning_rate": 0.0002676507650765076,
      "loss": 0.7001,
      "step": 2400
    },
    {
      "epoch": 2.205220522052205,
      "grad_norm": 1.1338385343551636,
      "learning_rate": 0.0002669756975697569,
      "loss": 0.7157,
      "step": 2450
    },
    {
      "epoch": 2.25022502250225,
      "grad_norm": 1.6671380996704102,
      "learning_rate": 0.0002663006300630063,
      "loss": 0.677,
      "step": 2500
    },
    {
      "epoch": 2.295229522952295,
      "grad_norm": 1.3906368017196655,
      "learning_rate": 0.0002656255625562556,
      "loss": 0.7051,
      "step": 2550
    },
    {
      "epoch": 2.34023402340234,
      "grad_norm": 1.193429708480835,
      "learning_rate": 0.00026495049504950493,
      "loss": 0.6699,
      "step": 2600
    },
    {
      "epoch": 2.385238523852385,
      "grad_norm": 0.9432618021965027,
      "learning_rate": 0.00026427542754275425,
      "loss": 0.7221,
      "step": 2650
    },
    {
      "epoch": 2.43024302430243,
      "grad_norm": 1.4265598058700562,
      "learning_rate": 0.00026360036003600357,
      "loss": 0.7015,
      "step": 2700
    },
    {
      "epoch": 2.4752475247524752,
      "grad_norm": 1.2270421981811523,
      "learning_rate": 0.00026292529252925294,
      "loss": 0.7093,
      "step": 2750
    },
    {
      "epoch": 2.5202520252025202,
      "grad_norm": 1.208984375,
      "learning_rate": 0.0002622502250225022,
      "loss": 0.7019,
      "step": 2800
    },
    {
      "epoch": 2.5652565256525652,
      "grad_norm": 1.059936285018921,
      "learning_rate": 0.00026157515751575153,
      "loss": 0.7024,
      "step": 2850
    },
    {
      "epoch": 2.6102610261026102,
      "grad_norm": 1.3300222158432007,
      "learning_rate": 0.00026090009000900085,
      "loss": 0.6868,
      "step": 2900
    },
    {
      "epoch": 2.6552655265526552,
      "grad_norm": 1.4050278663635254,
      "learning_rate": 0.00026022502250225017,
      "loss": 0.6736,
      "step": 2950
    },
    {
      "epoch": 2.7002700270027002,
      "grad_norm": 1.2795982360839844,
      "learning_rate": 0.00025954995499549954,
      "loss": 0.7093,
      "step": 3000
    },
    {
      "epoch": 2.7452745274527453,
      "grad_norm": 0.9266162514686584,
      "learning_rate": 0.00025887488748874886,
      "loss": 0.7026,
      "step": 3050
    },
    {
      "epoch": 2.7902790279027903,
      "grad_norm": 1.6318610906600952,
      "learning_rate": 0.0002581998199819982,
      "loss": 0.6979,
      "step": 3100
    },
    {
      "epoch": 2.8352835283528353,
      "grad_norm": 1.3533490896224976,
      "learning_rate": 0.0002575247524752475,
      "loss": 0.7234,
      "step": 3150
    },
    {
      "epoch": 2.8802880288028803,
      "grad_norm": 1.130566954612732,
      "learning_rate": 0.0002568496849684968,
      "loss": 0.7275,
      "step": 3200
    },
    {
      "epoch": 2.9252925292529253,
      "grad_norm": 1.27231764793396,
      "learning_rate": 0.0002561746174617462,
      "loss": 0.7199,
      "step": 3250
    },
    {
      "epoch": 2.9702970297029703,
      "grad_norm": 1.2802573442459106,
      "learning_rate": 0.0002554995499549955,
      "loss": 0.6948,
      "step": 3300
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7583545446395874,
      "eval_runtime": 19.2773,
      "eval_samples_per_second": 102.452,
      "eval_steps_per_second": 12.813,
      "step": 3333
    },
    {
      "epoch": 3.0153015301530153,
      "grad_norm": 1.4172052145004272,
      "learning_rate": 0.0002548244824482448,
      "loss": 0.7255,
      "step": 3350
    },
    {
      "epoch": 3.0603060306030603,
      "grad_norm": 1.0356682538986206,
      "learning_rate": 0.0002541494149414941,
      "loss": 0.6213,
      "step": 3400
    },
    {
      "epoch": 3.1053105310531053,
      "grad_norm": 1.3582994937896729,
      "learning_rate": 0.0002534743474347434,
      "loss": 0.6347,
      "step": 3450
    },
    {
      "epoch": 3.1503150315031503,
      "grad_norm": 1.1428964138031006,
      "learning_rate": 0.0002527992799279928,
      "loss": 0.6064,
      "step": 3500
    },
    {
      "epoch": 3.1953195319531953,
      "grad_norm": 1.2126219272613525,
      "learning_rate": 0.0002521242124212421,
      "loss": 0.6102,
      "step": 3550
    },
    {
      "epoch": 3.2403240324032403,
      "grad_norm": 1.2907015085220337,
      "learning_rate": 0.00025144914491449143,
      "loss": 0.6239,
      "step": 3600
    },
    {
      "epoch": 3.2853285328532853,
      "grad_norm": 1.178708553314209,
      "learning_rate": 0.00025077407740774075,
      "loss": 0.6174,
      "step": 3650
    },
    {
      "epoch": 3.3303330333033303,
      "grad_norm": 1.4957315921783447,
      "learning_rate": 0.00025009900990099007,
      "loss": 0.6258,
      "step": 3700
    },
    {
      "epoch": 3.3753375337533753,
      "grad_norm": 1.4446240663528442,
      "learning_rate": 0.00024942394239423944,
      "loss": 0.6373,
      "step": 3750
    },
    {
      "epoch": 3.4203420342034203,
      "grad_norm": 1.34714937210083,
      "learning_rate": 0.00024874887488748876,
      "loss": 0.6165,
      "step": 3800
    },
    {
      "epoch": 3.4653465346534653,
      "grad_norm": 1.3680105209350586,
      "learning_rate": 0.0002480738073807381,
      "loss": 0.6472,
      "step": 3850
    },
    {
      "epoch": 3.5103510351035103,
      "grad_norm": 1.1334525346755981,
      "learning_rate": 0.0002473987398739874,
      "loss": 0.6478,
      "step": 3900
    },
    {
      "epoch": 3.5553555355535553,
      "grad_norm": 1.3576979637145996,
      "learning_rate": 0.00024672367236723666,
      "loss": 0.6397,
      "step": 3950
    },
    {
      "epoch": 3.6003600360036003,
      "grad_norm": 1.498462200164795,
      "learning_rate": 0.00024604860486048604,
      "loss": 0.6544,
      "step": 4000
    },
    {
      "epoch": 3.6453645364536453,
      "grad_norm": 1.3625725507736206,
      "learning_rate": 0.00024537353735373536,
      "loss": 0.6986,
      "step": 4050
    },
    {
      "epoch": 3.6903690369036903,
      "grad_norm": 1.1894104480743408,
      "learning_rate": 0.0002446984698469847,
      "loss": 0.6413,
      "step": 4100
    },
    {
      "epoch": 3.7353735373537353,
      "grad_norm": 1.090927243232727,
      "learning_rate": 0.000244023402340234,
      "loss": 0.6705,
      "step": 4150
    },
    {
      "epoch": 3.7803780378037803,
      "grad_norm": 1.280012845993042,
      "learning_rate": 0.00024334833483348332,
      "loss": 0.6594,
      "step": 4200
    },
    {
      "epoch": 3.8253825382538253,
      "grad_norm": 1.463890790939331,
      "learning_rate": 0.00024267326732673266,
      "loss": 0.6254,
      "step": 4250
    },
    {
      "epoch": 3.8703870387038704,
      "grad_norm": 1.5248439311981201,
      "learning_rate": 0.00024199819981998198,
      "loss": 0.6442,
      "step": 4300
    },
    {
      "epoch": 3.9153915391539154,
      "grad_norm": 1.2928709983825684,
      "learning_rate": 0.0002413231323132313,
      "loss": 0.6136,
      "step": 4350
    },
    {
      "epoch": 3.9603960396039604,
      "grad_norm": 1.1502982378005981,
      "learning_rate": 0.00024064806480648062,
      "loss": 0.6913,
      "step": 4400
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.7831771969795227,
      "eval_runtime": 19.1544,
      "eval_samples_per_second": 103.109,
      "eval_steps_per_second": 12.895,
      "step": 4444
    },
    {
      "epoch": 4.005400540054006,
      "grad_norm": 1.0368374586105347,
      "learning_rate": 0.00023997299729972994,
      "loss": 0.6505,
      "step": 4450
    },
    {
      "epoch": 4.05040504050405,
      "grad_norm": 1.1686638593673706,
      "learning_rate": 0.00023929792979297929,
      "loss": 0.5597,
      "step": 4500
    },
    {
      "epoch": 4.095409540954096,
      "grad_norm": 1.3272451162338257,
      "learning_rate": 0.0002386228622862286,
      "loss": 0.5517,
      "step": 4550
    },
    {
      "epoch": 4.14041404140414,
      "grad_norm": 1.6631062030792236,
      "learning_rate": 0.00023794779477947793,
      "loss": 0.6156,
      "step": 4600
    },
    {
      "epoch": 4.185418541854186,
      "grad_norm": 1.0813628435134888,
      "learning_rate": 0.00023727272727272724,
      "loss": 0.5783,
      "step": 4650
    },
    {
      "epoch": 4.23042304230423,
      "grad_norm": 1.146531105041504,
      "learning_rate": 0.00023659765976597656,
      "loss": 0.5621,
      "step": 4700
    },
    {
      "epoch": 4.275427542754276,
      "grad_norm": 1.387236475944519,
      "learning_rate": 0.0002359225922592259,
      "loss": 0.5957,
      "step": 4750
    },
    {
      "epoch": 4.32043204320432,
      "grad_norm": 1.193784236907959,
      "learning_rate": 0.00023524752475247523,
      "loss": 0.593,
      "step": 4800
    },
    {
      "epoch": 4.365436543654366,
      "grad_norm": 1.0278370380401611,
      "learning_rate": 0.00023457245724572455,
      "loss": 0.5356,
      "step": 4850
    },
    {
      "epoch": 4.41044104410441,
      "grad_norm": 1.4840283393859863,
      "learning_rate": 0.00023389738973897387,
      "loss": 0.6357,
      "step": 4900
    },
    {
      "epoch": 4.455445544554456,
      "grad_norm": 1.8853026628494263,
      "learning_rate": 0.0002332223222322232,
      "loss": 0.6046,
      "step": 4950
    },
    {
      "epoch": 4.5004500450045,
      "grad_norm": 1.262110710144043,
      "learning_rate": 0.00023254725472547253,
      "loss": 0.5931,
      "step": 5000
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 1.9989241361618042,
      "learning_rate": 0.00023187218721872185,
      "loss": 0.5971,
      "step": 5050
    },
    {
      "epoch": 4.59045904590459,
      "grad_norm": 1.2326265573501587,
      "learning_rate": 0.00023119711971197117,
      "loss": 0.5778,
      "step": 5100
    },
    {
      "epoch": 4.635463546354636,
      "grad_norm": 1.3264260292053223,
      "learning_rate": 0.00023053555355535553,
      "loss": 0.5885,
      "step": 5150
    },
    {
      "epoch": 4.68046804680468,
      "grad_norm": 1.3682239055633545,
      "learning_rate": 0.00022986048604860485,
      "loss": 0.5063,
      "step": 5200
    },
    {
      "epoch": 4.725472547254725,
      "grad_norm": 1.4495453834533691,
      "learning_rate": 0.00022918541854185416,
      "loss": 0.6118,
      "step": 5250
    },
    {
      "epoch": 4.77047704770477,
      "grad_norm": 1.319442629814148,
      "learning_rate": 0.00022851035103510348,
      "loss": 0.6018,
      "step": 5300
    },
    {
      "epoch": 4.815481548154816,
      "grad_norm": 1.6019195318222046,
      "learning_rate": 0.00022783528352835283,
      "loss": 0.6218,
      "step": 5350
    },
    {
      "epoch": 4.86048604860486,
      "grad_norm": 1.1531903743743896,
      "learning_rate": 0.00022716021602160215,
      "loss": 0.5979,
      "step": 5400
    },
    {
      "epoch": 4.905490549054905,
      "grad_norm": 1.0698915719985962,
      "learning_rate": 0.00022648514851485147,
      "loss": 0.5974,
      "step": 5450
    },
    {
      "epoch": 4.9504950495049505,
      "grad_norm": 1.1847712993621826,
      "learning_rate": 0.0002258100810081008,
      "loss": 0.6366,
      "step": 5500
    },
    {
      "epoch": 4.995499549954996,
      "grad_norm": 1.3665610551834106,
      "learning_rate": 0.0002251350135013501,
      "loss": 0.6155,
      "step": 5550
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7798054218292236,
      "eval_runtime": 19.2628,
      "eval_samples_per_second": 102.529,
      "eval_steps_per_second": 12.823,
      "step": 5555
    },
    {
      "epoch": 5.0405040504050405,
      "grad_norm": 1.3333415985107422,
      "learning_rate": 0.00022445994599459945,
      "loss": 0.5359,
      "step": 5600
    },
    {
      "epoch": 5.085508550855086,
      "grad_norm": 1.3794599771499634,
      "learning_rate": 0.00022378487848784877,
      "loss": 0.5603,
      "step": 5650
    },
    {
      "epoch": 5.1305130513051305,
      "grad_norm": 1.5557479858398438,
      "learning_rate": 0.0002231098109810981,
      "loss": 0.5475,
      "step": 5700
    },
    {
      "epoch": 5.175517551755176,
      "grad_norm": 1.448327660560608,
      "learning_rate": 0.0002224347434743474,
      "loss": 0.5278,
      "step": 5750
    },
    {
      "epoch": 5.2205220522052205,
      "grad_norm": 0.9502004981040955,
      "learning_rate": 0.00022175967596759673,
      "loss": 0.5606,
      "step": 5800
    },
    {
      "epoch": 5.265526552655266,
      "grad_norm": 1.2082329988479614,
      "learning_rate": 0.00022108460846084608,
      "loss": 0.5207,
      "step": 5850
    },
    {
      "epoch": 5.3105310531053105,
      "grad_norm": 1.2997781038284302,
      "learning_rate": 0.0002204095409540954,
      "loss": 0.6053,
      "step": 5900
    },
    {
      "epoch": 5.355535553555356,
      "grad_norm": 1.6643245220184326,
      "learning_rate": 0.00021973447344734472,
      "loss": 0.5546,
      "step": 5950
    },
    {
      "epoch": 5.4005400540054005,
      "grad_norm": 1.484474778175354,
      "learning_rate": 0.00021905940594059404,
      "loss": 0.5045,
      "step": 6000
    },
    {
      "epoch": 5.445544554455446,
      "grad_norm": 1.661630392074585,
      "learning_rate": 0.00021838433843384336,
      "loss": 0.5534,
      "step": 6050
    },
    {
      "epoch": 5.4905490549054905,
      "grad_norm": 0.9648944139480591,
      "learning_rate": 0.0002177092709270927,
      "loss": 0.5437,
      "step": 6100
    },
    {
      "epoch": 5.535553555355536,
      "grad_norm": 1.531927466392517,
      "learning_rate": 0.00021703420342034202,
      "loss": 0.543,
      "step": 6150
    },
    {
      "epoch": 5.5805580558055805,
      "grad_norm": 1.3485307693481445,
      "learning_rate": 0.00021635913591359134,
      "loss": 0.5298,
      "step": 6200
    },
    {
      "epoch": 5.625562556255625,
      "grad_norm": 1.6807013750076294,
      "learning_rate": 0.00021568406840684066,
      "loss": 0.5699,
      "step": 6250
    },
    {
      "epoch": 5.6705670567056705,
      "grad_norm": 1.4080772399902344,
      "learning_rate": 0.00021500900090008998,
      "loss": 0.566,
      "step": 6300
    },
    {
      "epoch": 5.715571557155716,
      "grad_norm": 1.5711312294006348,
      "learning_rate": 0.00021433393339333933,
      "loss": 0.5277,
      "step": 6350
    },
    {
      "epoch": 5.7605760576057605,
      "grad_norm": 1.3120733499526978,
      "learning_rate": 0.00021365886588658865,
      "loss": 0.5797,
      "step": 6400
    },
    {
      "epoch": 5.805580558055805,
      "grad_norm": 1.0247774124145508,
      "learning_rate": 0.00021298379837983797,
      "loss": 0.5363,
      "step": 6450
    },
    {
      "epoch": 5.8505850585058505,
      "grad_norm": 1.6115034818649292,
      "learning_rate": 0.00021230873087308729,
      "loss": 0.5454,
      "step": 6500
    },
    {
      "epoch": 5.895589558955896,
      "grad_norm": 1.7762433290481567,
      "learning_rate": 0.0002116336633663366,
      "loss": 0.5477,
      "step": 6550
    },
    {
      "epoch": 5.9405940594059405,
      "grad_norm": 1.649709939956665,
      "learning_rate": 0.00021095859585958595,
      "loss": 0.5383,
      "step": 6600
    },
    {
      "epoch": 5.985598559855985,
      "grad_norm": 1.4454673528671265,
      "learning_rate": 0.00021028352835283527,
      "loss": 0.5689,
      "step": 6650
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7953459024429321,
      "eval_runtime": 19.1216,
      "eval_samples_per_second": 103.286,
      "eval_steps_per_second": 12.917,
      "step": 6666
    }
  ],
  "logging_steps": 50,
  "max_steps": 22220,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 3
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 793162961682432.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
