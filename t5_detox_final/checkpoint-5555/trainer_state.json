{
  "best_global_step": 2222,
  "best_metric": 0.9051622152328491,
  "best_model_checkpoint": "./t5_detox_final\\checkpoint-2222",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 5555,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.045004500450045004,
      "grad_norm": 2.0154647827148438,
      "learning_rate": 0.0002993654365436543,
      "loss": 1.4482,
      "step": 50
    },
    {
      "epoch": 0.09000900090009001,
      "grad_norm": 1.6389596462249756,
      "learning_rate": 0.00029869036903690363,
      "loss": 1.195,
      "step": 100
    },
    {
      "epoch": 0.135013501350135,
      "grad_norm": 1.825034260749817,
      "learning_rate": 0.000298015301530153,
      "loss": 1.2116,
      "step": 150
    },
    {
      "epoch": 0.18001800180018002,
      "grad_norm": 1.884415626525879,
      "learning_rate": 0.0002973402340234023,
      "loss": 1.152,
      "step": 200
    },
    {
      "epoch": 0.22502250225022502,
      "grad_norm": 2.1500020027160645,
      "learning_rate": 0.00029666516651665164,
      "loss": 1.0584,
      "step": 250
    },
    {
      "epoch": 0.27002700270027,
      "grad_norm": 1.7431703805923462,
      "learning_rate": 0.00029599009900990096,
      "loss": 1.1472,
      "step": 300
    },
    {
      "epoch": 0.31503150315031503,
      "grad_norm": 2.091026782989502,
      "learning_rate": 0.0002953150315031503,
      "loss": 1.081,
      "step": 350
    },
    {
      "epoch": 0.36003600360036003,
      "grad_norm": 1.8613418340682983,
      "learning_rate": 0.00029463996399639966,
      "loss": 1.1034,
      "step": 400
    },
    {
      "epoch": 0.40504050405040504,
      "grad_norm": 1.6862574815750122,
      "learning_rate": 0.000293964896489649,
      "loss": 1.1086,
      "step": 450
    },
    {
      "epoch": 0.45004500450045004,
      "grad_norm": 1.2661118507385254,
      "learning_rate": 0.0002932898289828983,
      "loss": 1.1087,
      "step": 500
    },
    {
      "epoch": 0.49504950495049505,
      "grad_norm": 2.0516228675842285,
      "learning_rate": 0.00029261476147614756,
      "loss": 1.0948,
      "step": 550
    },
    {
      "epoch": 0.54005400540054,
      "grad_norm": 1.6659011840820312,
      "learning_rate": 0.0002919396939693969,
      "loss": 1.0711,
      "step": 600
    },
    {
      "epoch": 0.585058505850585,
      "grad_norm": 1.6304221153259277,
      "learning_rate": 0.00029126462646264625,
      "loss": 1.0027,
      "step": 650
    },
    {
      "epoch": 0.6300630063006301,
      "grad_norm": 1.3939471244812012,
      "learning_rate": 0.00029058955895589557,
      "loss": 1.0709,
      "step": 700
    },
    {
      "epoch": 0.6750675067506751,
      "grad_norm": 1.1955708265304565,
      "learning_rate": 0.0002899144914491449,
      "loss": 1.093,
      "step": 750
    },
    {
      "epoch": 0.7200720072007201,
      "grad_norm": 1.4957069158554077,
      "learning_rate": 0.0002892394239423942,
      "loss": 1.0396,
      "step": 800
    },
    {
      "epoch": 0.7650765076507651,
      "grad_norm": 1.2631276845932007,
      "learning_rate": 0.00028856435643564353,
      "loss": 1.067,
      "step": 850
    },
    {
      "epoch": 0.8100810081008101,
      "grad_norm": 1.70028817653656,
      "learning_rate": 0.0002878892889288929,
      "loss": 1.0691,
      "step": 900
    },
    {
      "epoch": 0.8550855085508551,
      "grad_norm": 1.5598214864730835,
      "learning_rate": 0.0002872142214221422,
      "loss": 0.9938,
      "step": 950
    },
    {
      "epoch": 0.9000900090009001,
      "grad_norm": 1.4279632568359375,
      "learning_rate": 0.00028653915391539154,
      "loss": 1.0638,
      "step": 1000
    },
    {
      "epoch": 0.9450945094509451,
      "grad_norm": 1.3959795236587524,
      "learning_rate": 0.00028586408640864086,
      "loss": 1.0526,
      "step": 1050
    },
    {
      "epoch": 0.9900990099009901,
      "grad_norm": 2.7734458446502686,
      "learning_rate": 0.00028518901890189013,
      "loss": 1.0093,
      "step": 1100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.9216297268867493,
      "eval_runtime": 5.5663,
      "eval_samples_per_second": 354.815,
      "eval_steps_per_second": 44.374,
      "step": 1111
    },
    {
      "epoch": 1.035103510351035,
      "grad_norm": 1.5434426069259644,
      "learning_rate": 0.0002845274527452745,
      "loss": 0.9404,
      "step": 1150
    },
    {
      "epoch": 1.08010801080108,
      "grad_norm": 1.4206135272979736,
      "learning_rate": 0.0002838523852385238,
      "loss": 0.9213,
      "step": 1200
    },
    {
      "epoch": 1.125112511251125,
      "grad_norm": 1.8578118085861206,
      "learning_rate": 0.00028317731773177315,
      "loss": 0.9417,
      "step": 1250
    },
    {
      "epoch": 1.17011701170117,
      "grad_norm": 1.122532844543457,
      "learning_rate": 0.00028250225022502246,
      "loss": 0.9446,
      "step": 1300
    },
    {
      "epoch": 1.215121512151215,
      "grad_norm": 0.8828274607658386,
      "learning_rate": 0.0002818271827182718,
      "loss": 0.9138,
      "step": 1350
    },
    {
      "epoch": 1.2601260126012601,
      "grad_norm": 1.6269811391830444,
      "learning_rate": 0.0002811521152115211,
      "loss": 0.9396,
      "step": 1400
    },
    {
      "epoch": 1.3051305130513051,
      "grad_norm": 1.101405143737793,
      "learning_rate": 0.0002804770477047704,
      "loss": 0.9372,
      "step": 1450
    },
    {
      "epoch": 1.3501350135013501,
      "grad_norm": 1.1777411699295044,
      "learning_rate": 0.0002798019801980198,
      "loss": 0.9497,
      "step": 1500
    },
    {
      "epoch": 1.3951395139513951,
      "grad_norm": 1.747157335281372,
      "learning_rate": 0.0002791269126912691,
      "loss": 0.9339,
      "step": 1550
    },
    {
      "epoch": 1.4401440144014401,
      "grad_norm": 1.4140093326568604,
      "learning_rate": 0.00027845184518451844,
      "loss": 0.9695,
      "step": 1600
    },
    {
      "epoch": 1.4851485148514851,
      "grad_norm": 1.483628273010254,
      "learning_rate": 0.00027777677767776776,
      "loss": 0.8974,
      "step": 1650
    },
    {
      "epoch": 1.5301530153015301,
      "grad_norm": 1.816208004951477,
      "learning_rate": 0.0002771017101710171,
      "loss": 0.9524,
      "step": 1700
    },
    {
      "epoch": 1.5751575157515751,
      "grad_norm": 1.2999436855316162,
      "learning_rate": 0.0002764266426642664,
      "loss": 0.9658,
      "step": 1750
    },
    {
      "epoch": 1.6201620162016201,
      "grad_norm": 1.5441961288452148,
      "learning_rate": 0.0002757515751575157,
      "loss": 0.9326,
      "step": 1800
    },
    {
      "epoch": 1.6651665166516652,
      "grad_norm": 1.3490417003631592,
      "learning_rate": 0.00027507650765076503,
      "loss": 0.8834,
      "step": 1850
    },
    {
      "epoch": 1.7101710171017102,
      "grad_norm": 1.3560130596160889,
      "learning_rate": 0.00027440144014401435,
      "loss": 0.898,
      "step": 1900
    },
    {
      "epoch": 1.7551755175517552,
      "grad_norm": 1.5331799983978271,
      "learning_rate": 0.00027372637263726367,
      "loss": 0.8918,
      "step": 1950
    },
    {
      "epoch": 1.8001800180018002,
      "grad_norm": 1.5717980861663818,
      "learning_rate": 0.00027305130513051305,
      "loss": 0.9037,
      "step": 2000
    },
    {
      "epoch": 1.8451845184518452,
      "grad_norm": 1.443061113357544,
      "learning_rate": 0.00027237623762376236,
      "loss": 0.9153,
      "step": 2050
    },
    {
      "epoch": 1.8901890189018902,
      "grad_norm": 1.5787156820297241,
      "learning_rate": 0.0002717011701170117,
      "loss": 0.9187,
      "step": 2100
    },
    {
      "epoch": 1.9351935193519352,
      "grad_norm": 1.9170230627059937,
      "learning_rate": 0.000271026102610261,
      "loss": 0.9149,
      "step": 2150
    },
    {
      "epoch": 1.9801980198019802,
      "grad_norm": 1.1418401002883911,
      "learning_rate": 0.0002703510351035103,
      "loss": 0.906,
      "step": 2200
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.9051622152328491,
      "eval_runtime": 5.5336,
      "eval_samples_per_second": 356.909,
      "eval_steps_per_second": 44.636,
      "step": 2222
    },
    {
      "epoch": 2.025202520252025,
      "grad_norm": 1.190485954284668,
      "learning_rate": 0.00026968946894689465,
      "loss": 0.8651,
      "step": 2250
    },
    {
      "epoch": 2.07020702070207,
      "grad_norm": 1.5915042161941528,
      "learning_rate": 0.00026901440144014397,
      "loss": 0.8819,
      "step": 2300
    },
    {
      "epoch": 2.115211521152115,
      "grad_norm": 1.6069461107254028,
      "learning_rate": 0.00026833933393339334,
      "loss": 0.8202,
      "step": 2350
    },
    {
      "epoch": 2.16021602160216,
      "grad_norm": 1.018611192703247,
      "learning_rate": 0.00026766426642664266,
      "loss": 0.8457,
      "step": 2400
    },
    {
      "epoch": 2.205220522052205,
      "grad_norm": 1.1404541730880737,
      "learning_rate": 0.000266989198919892,
      "loss": 0.8487,
      "step": 2450
    },
    {
      "epoch": 2.25022502250225,
      "grad_norm": 1.451236367225647,
      "learning_rate": 0.0002663141314131413,
      "loss": 0.8042,
      "step": 2500
    },
    {
      "epoch": 2.295229522952295,
      "grad_norm": 1.4770323038101196,
      "learning_rate": 0.0002656390639063906,
      "loss": 0.8554,
      "step": 2550
    },
    {
      "epoch": 2.34023402340234,
      "grad_norm": 1.4606672525405884,
      "learning_rate": 0.00026496399639963994,
      "loss": 0.8049,
      "step": 2600
    },
    {
      "epoch": 2.385238523852385,
      "grad_norm": 1.1351430416107178,
      "learning_rate": 0.00026428892889288926,
      "loss": 0.8464,
      "step": 2650
    },
    {
      "epoch": 2.43024302430243,
      "grad_norm": 1.4167309999465942,
      "learning_rate": 0.0002636138613861386,
      "loss": 0.8424,
      "step": 2700
    },
    {
      "epoch": 2.4752475247524752,
      "grad_norm": 1.4735541343688965,
      "learning_rate": 0.0002629387938793879,
      "loss": 0.8313,
      "step": 2750
    },
    {
      "epoch": 2.5202520252025202,
      "grad_norm": 1.2477563619613647,
      "learning_rate": 0.0002622637263726372,
      "loss": 0.8222,
      "step": 2800
    },
    {
      "epoch": 2.5652565256525652,
      "grad_norm": 1.172566294670105,
      "learning_rate": 0.0002615886588658866,
      "loss": 0.8186,
      "step": 2850
    },
    {
      "epoch": 2.6102610261026102,
      "grad_norm": 1.1763836145401,
      "learning_rate": 0.0002609135913591359,
      "loss": 0.8333,
      "step": 2900
    },
    {
      "epoch": 2.6552655265526552,
      "grad_norm": 1.7150328159332275,
      "learning_rate": 0.00026023852385238523,
      "loss": 0.798,
      "step": 2950
    },
    {
      "epoch": 2.7002700270027002,
      "grad_norm": 1.6281893253326416,
      "learning_rate": 0.00025956345634563455,
      "loss": 0.8515,
      "step": 3000
    },
    {
      "epoch": 2.7452745274527453,
      "grad_norm": 1.2169859409332275,
      "learning_rate": 0.00025888838883888387,
      "loss": 0.8394,
      "step": 3050
    },
    {
      "epoch": 2.7902790279027903,
      "grad_norm": 1.5661474466323853,
      "learning_rate": 0.0002582133213321332,
      "loss": 0.8221,
      "step": 3100
    },
    {
      "epoch": 2.8352835283528353,
      "grad_norm": 1.7355289459228516,
      "learning_rate": 0.0002575382538253825,
      "loss": 0.8358,
      "step": 3150
    },
    {
      "epoch": 2.8802880288028803,
      "grad_norm": 1.61358642578125,
      "learning_rate": 0.0002568631863186318,
      "loss": 0.8624,
      "step": 3200
    },
    {
      "epoch": 2.9252925292529253,
      "grad_norm": 1.5685391426086426,
      "learning_rate": 0.00025618811881188114,
      "loss": 0.8465,
      "step": 3250
    },
    {
      "epoch": 2.9702970297029703,
      "grad_norm": 1.1923894882202148,
      "learning_rate": 0.00025551305130513046,
      "loss": 0.8157,
      "step": 3300
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.9074386954307556,
      "eval_runtime": 5.5864,
      "eval_samples_per_second": 353.537,
      "eval_steps_per_second": 44.214,
      "step": 3333
    },
    {
      "epoch": 3.0153015301530153,
      "grad_norm": 1.1915086507797241,
      "learning_rate": 0.00025483798379837984,
      "loss": 0.8394,
      "step": 3350
    },
    {
      "epoch": 3.0603060306030603,
      "grad_norm": 1.298191785812378,
      "learning_rate": 0.00025416291629162916,
      "loss": 0.7459,
      "step": 3400
    },
    {
      "epoch": 3.1053105310531053,
      "grad_norm": 1.0491604804992676,
      "learning_rate": 0.0002534878487848785,
      "loss": 0.7618,
      "step": 3450
    },
    {
      "epoch": 3.1503150315031503,
      "grad_norm": 1.115852952003479,
      "learning_rate": 0.0002528127812781278,
      "loss": 0.732,
      "step": 3500
    },
    {
      "epoch": 3.1953195319531953,
      "grad_norm": 1.2053897380828857,
      "learning_rate": 0.0002521377137713771,
      "loss": 0.7487,
      "step": 3550
    },
    {
      "epoch": 3.2403240324032403,
      "grad_norm": 1.2258338928222656,
      "learning_rate": 0.00025146264626462643,
      "loss": 0.7495,
      "step": 3600
    },
    {
      "epoch": 3.2853285328532853,
      "grad_norm": 1.9004322290420532,
      "learning_rate": 0.00025078757875787575,
      "loss": 0.7385,
      "step": 3650
    },
    {
      "epoch": 3.3303330333033303,
      "grad_norm": 1.2412967681884766,
      "learning_rate": 0.0002501125112511251,
      "loss": 0.7579,
      "step": 3700
    },
    {
      "epoch": 3.3753375337533753,
      "grad_norm": 1.5320136547088623,
      "learning_rate": 0.0002494374437443744,
      "loss": 0.7652,
      "step": 3750
    },
    {
      "epoch": 3.4203420342034203,
      "grad_norm": 1.3534729480743408,
      "learning_rate": 0.0002487623762376237,
      "loss": 0.7222,
      "step": 3800
    },
    {
      "epoch": 3.4653465346534653,
      "grad_norm": 1.4012490510940552,
      "learning_rate": 0.0002480873087308731,
      "loss": 0.793,
      "step": 3850
    },
    {
      "epoch": 3.5103510351035103,
      "grad_norm": 1.2507805824279785,
      "learning_rate": 0.0002474122412241224,
      "loss": 0.79,
      "step": 3900
    },
    {
      "epoch": 3.5553555355535553,
      "grad_norm": 1.6976944208145142,
      "learning_rate": 0.0002467371737173717,
      "loss": 0.7768,
      "step": 3950
    },
    {
      "epoch": 3.6003600360036003,
      "grad_norm": 1.3623594045639038,
      "learning_rate": 0.00024606210621062104,
      "loss": 0.7789,
      "step": 4000
    },
    {
      "epoch": 3.6453645364536453,
      "grad_norm": 1.1020870208740234,
      "learning_rate": 0.00024538703870387036,
      "loss": 0.8267,
      "step": 4050
    },
    {
      "epoch": 3.6903690369036903,
      "grad_norm": 1.3815244436264038,
      "learning_rate": 0.0002447119711971197,
      "loss": 0.7644,
      "step": 4100
    },
    {
      "epoch": 3.7353735373537353,
      "grad_norm": 1.9159889221191406,
      "learning_rate": 0.00024403690369036903,
      "loss": 0.7914,
      "step": 4150
    },
    {
      "epoch": 3.7803780378037803,
      "grad_norm": 1.1244940757751465,
      "learning_rate": 0.00024336183618361835,
      "loss": 0.7778,
      "step": 4200
    },
    {
      "epoch": 3.8253825382538253,
      "grad_norm": 1.3441123962402344,
      "learning_rate": 0.00024268676867686767,
      "loss": 0.758,
      "step": 4250
    },
    {
      "epoch": 3.8703870387038704,
      "grad_norm": 1.3651927709579468,
      "learning_rate": 0.000242011701170117,
      "loss": 0.7723,
      "step": 4300
    },
    {
      "epoch": 3.9153915391539154,
      "grad_norm": 1.6067843437194824,
      "learning_rate": 0.00024133663366336633,
      "loss": 0.7406,
      "step": 4350
    },
    {
      "epoch": 3.9603960396039604,
      "grad_norm": 1.227552890777588,
      "learning_rate": 0.00024066156615661565,
      "loss": 0.8245,
      "step": 4400
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.9197024703025818,
      "eval_runtime": 5.551,
      "eval_samples_per_second": 355.793,
      "eval_steps_per_second": 44.497,
      "step": 4444
    },
    {
      "epoch": 4.005400540054006,
      "grad_norm": 1.2797290086746216,
      "learning_rate": 0.00023998649864986497,
      "loss": 0.7788,
      "step": 4450
    },
    {
      "epoch": 4.05040504050405,
      "grad_norm": 1.5924819707870483,
      "learning_rate": 0.0002393114311431143,
      "loss": 0.6743,
      "step": 4500
    },
    {
      "epoch": 4.095409540954096,
      "grad_norm": 1.9439631700515747,
      "learning_rate": 0.0002386363636363636,
      "loss": 0.669,
      "step": 4550
    },
    {
      "epoch": 4.14041404140414,
      "grad_norm": 1.4763164520263672,
      "learning_rate": 0.00023796129612961296,
      "loss": 0.7516,
      "step": 4600
    },
    {
      "epoch": 4.185418541854186,
      "grad_norm": 1.3318365812301636,
      "learning_rate": 0.00023728622862286228,
      "loss": 0.715,
      "step": 4650
    },
    {
      "epoch": 4.23042304230423,
      "grad_norm": 1.1579492092132568,
      "learning_rate": 0.0002366111611161116,
      "loss": 0.6966,
      "step": 4700
    },
    {
      "epoch": 4.275427542754276,
      "grad_norm": 1.0717347860336304,
      "learning_rate": 0.00023593609360936092,
      "loss": 0.7196,
      "step": 4750
    },
    {
      "epoch": 4.32043204320432,
      "grad_norm": 1.3015273809432983,
      "learning_rate": 0.00023526102610261024,
      "loss": 0.7026,
      "step": 4800
    },
    {
      "epoch": 4.365436543654366,
      "grad_norm": 1.3190215826034546,
      "learning_rate": 0.00023458595859585958,
      "loss": 0.6672,
      "step": 4850
    },
    {
      "epoch": 4.41044104410441,
      "grad_norm": 1.7565850019454956,
      "learning_rate": 0.0002339108910891089,
      "loss": 0.7406,
      "step": 4900
    },
    {
      "epoch": 4.455445544554456,
      "grad_norm": 1.4874179363250732,
      "learning_rate": 0.00023323582358235822,
      "loss": 0.7306,
      "step": 4950
    },
    {
      "epoch": 4.5004500450045,
      "grad_norm": 1.818177580833435,
      "learning_rate": 0.00023256075607560754,
      "loss": 0.7155,
      "step": 5000
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 1.751242756843567,
      "learning_rate": 0.00023188568856885686,
      "loss": 0.7184,
      "step": 5050
    },
    {
      "epoch": 4.59045904590459,
      "grad_norm": 0.9507765769958496,
      "learning_rate": 0.0002312106210621062,
      "loss": 0.7022,
      "step": 5100
    },
    {
      "epoch": 4.635463546354636,
      "grad_norm": 1.6455029249191284,
      "learning_rate": 0.00023053555355535553,
      "loss": 0.7088,
      "step": 5150
    },
    {
      "epoch": 4.68046804680468,
      "grad_norm": 1.870789647102356,
      "learning_rate": 0.00022986048604860485,
      "loss": 0.6343,
      "step": 5200
    },
    {
      "epoch": 4.725472547254725,
      "grad_norm": 1.6271371841430664,
      "learning_rate": 0.00022918541854185416,
      "loss": 0.7393,
      "step": 5250
    },
    {
      "epoch": 4.77047704770477,
      "grad_norm": 1.6861114501953125,
      "learning_rate": 0.00022851035103510348,
      "loss": 0.7291,
      "step": 5300
    },
    {
      "epoch": 4.815481548154816,
      "grad_norm": 2.5443501472473145,
      "learning_rate": 0.00022783528352835283,
      "loss": 0.7321,
      "step": 5350
    },
    {
      "epoch": 4.86048604860486,
      "grad_norm": 1.4267456531524658,
      "learning_rate": 0.00022716021602160215,
      "loss": 0.7294,
      "step": 5400
    },
    {
      "epoch": 4.905490549054905,
      "grad_norm": 1.2726482152938843,
      "learning_rate": 0.00022648514851485147,
      "loss": 0.7284,
      "step": 5450
    },
    {
      "epoch": 4.9504950495049505,
      "grad_norm": 1.0360758304595947,
      "learning_rate": 0.0002258100810081008,
      "loss": 0.7633,
      "step": 5500
    },
    {
      "epoch": 4.995499549954996,
      "grad_norm": 1.1776683330535889,
      "learning_rate": 0.0002251350135013501,
      "loss": 0.7245,
      "step": 5550
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.9371337294578552,
      "eval_runtime": 5.5636,
      "eval_samples_per_second": 354.983,
      "eval_steps_per_second": 44.395,
      "step": 5555
    }
  ],
  "logging_steps": 50,
  "max_steps": 22220,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 3
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 744993175633920.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
