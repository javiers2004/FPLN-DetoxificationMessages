{
  "best_global_step": 2222,
  "best_metric": 0.9025762677192688,
  "best_model_checkpoint": "./t5_detox_final\\checkpoint-2222",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 5555,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.045004500450045004,
      "grad_norm": 2.420064926147461,
      "learning_rate": 0.00029937893789378937,
      "loss": 1.4434,
      "step": 50
    },
    {
      "epoch": 0.09000900090009001,
      "grad_norm": 1.744619607925415,
      "learning_rate": 0.0002987038703870387,
      "loss": 1.2075,
      "step": 100
    },
    {
      "epoch": 0.135013501350135,
      "grad_norm": 1.7528218030929565,
      "learning_rate": 0.000298028802880288,
      "loss": 1.1963,
      "step": 150
    },
    {
      "epoch": 0.18001800180018002,
      "grad_norm": 1.6274595260620117,
      "learning_rate": 0.00029735373537353733,
      "loss": 1.1497,
      "step": 200
    },
    {
      "epoch": 0.22502250225022502,
      "grad_norm": 1.6058359146118164,
      "learning_rate": 0.00029667866786678665,
      "loss": 1.0739,
      "step": 250
    },
    {
      "epoch": 0.27002700270027,
      "grad_norm": 1.8669813871383667,
      "learning_rate": 0.00029600360036003597,
      "loss": 1.1408,
      "step": 300
    },
    {
      "epoch": 0.31503150315031503,
      "grad_norm": 1.7492386102676392,
      "learning_rate": 0.0002953285328532853,
      "loss": 1.0786,
      "step": 350
    },
    {
      "epoch": 0.36003600360036003,
      "grad_norm": 1.3954342603683472,
      "learning_rate": 0.0002946534653465346,
      "loss": 1.104,
      "step": 400
    },
    {
      "epoch": 0.40504050405040504,
      "grad_norm": 1.8871071338653564,
      "learning_rate": 0.0002939783978397839,
      "loss": 1.0995,
      "step": 450
    },
    {
      "epoch": 0.45004500450045004,
      "grad_norm": 1.287102460861206,
      "learning_rate": 0.0002933033303330333,
      "loss": 1.1127,
      "step": 500
    },
    {
      "epoch": 0.49504950495049505,
      "grad_norm": 1.3386048078536987,
      "learning_rate": 0.0002926282628262826,
      "loss": 1.0919,
      "step": 550
    },
    {
      "epoch": 0.54005400540054,
      "grad_norm": 1.7804936170578003,
      "learning_rate": 0.00029195319531953194,
      "loss": 1.0694,
      "step": 600
    },
    {
      "epoch": 0.585058505850585,
      "grad_norm": 1.5431673526763916,
      "learning_rate": 0.00029127812781278126,
      "loss": 1.0153,
      "step": 650
    },
    {
      "epoch": 0.6300630063006301,
      "grad_norm": 1.2801581621170044,
      "learning_rate": 0.0002906030603060306,
      "loss": 1.0822,
      "step": 700
    },
    {
      "epoch": 0.6750675067506751,
      "grad_norm": 1.492849349975586,
      "learning_rate": 0.0002899279927992799,
      "loss": 1.0891,
      "step": 750
    },
    {
      "epoch": 0.7200720072007201,
      "grad_norm": 1.22429358959198,
      "learning_rate": 0.0002892529252925292,
      "loss": 1.0442,
      "step": 800
    },
    {
      "epoch": 0.7650765076507651,
      "grad_norm": 1.0576858520507812,
      "learning_rate": 0.00028857785778577854,
      "loss": 1.0749,
      "step": 850
    },
    {
      "epoch": 0.8100810081008101,
      "grad_norm": 1.2774516344070435,
      "learning_rate": 0.00028790279027902786,
      "loss": 1.0683,
      "step": 900
    },
    {
      "epoch": 0.8550855085508551,
      "grad_norm": 1.8521814346313477,
      "learning_rate": 0.0002872277227722772,
      "loss": 0.9938,
      "step": 950
    },
    {
      "epoch": 0.9000900090009001,
      "grad_norm": 2.0650248527526855,
      "learning_rate": 0.00028655265526552655,
      "loss": 1.0586,
      "step": 1000
    },
    {
      "epoch": 0.9450945094509451,
      "grad_norm": 1.3961591720581055,
      "learning_rate": 0.00028587758775877587,
      "loss": 1.0466,
      "step": 1050
    },
    {
      "epoch": 0.9900990099009901,
      "grad_norm": 2.1762819290161133,
      "learning_rate": 0.0002852025202520252,
      "loss": 1.0074,
      "step": 1100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.9198208451271057,
      "eval_runtime": 21.5244,
      "eval_samples_per_second": 91.757,
      "eval_steps_per_second": 11.475,
      "step": 1111
    },
    {
      "epoch": 1.035103510351035,
      "grad_norm": 1.6191790103912354,
      "learning_rate": 0.0002845409540954095,
      "loss": 0.9365,
      "step": 1150
    },
    {
      "epoch": 1.08010801080108,
      "grad_norm": 1.7258583307266235,
      "learning_rate": 0.00028386588658865883,
      "loss": 0.9221,
      "step": 1200
    },
    {
      "epoch": 1.125112511251125,
      "grad_norm": 2.0060598850250244,
      "learning_rate": 0.00028319081908190815,
      "loss": 0.9574,
      "step": 1250
    },
    {
      "epoch": 1.17011701170117,
      "grad_norm": 1.1945743560791016,
      "learning_rate": 0.00028251575157515747,
      "loss": 0.9407,
      "step": 1300
    },
    {
      "epoch": 1.215121512151215,
      "grad_norm": 1.399472713470459,
      "learning_rate": 0.00028184068406840684,
      "loss": 0.9315,
      "step": 1350
    },
    {
      "epoch": 1.2601260126012601,
      "grad_norm": 1.4804149866104126,
      "learning_rate": 0.00028116561656165616,
      "loss": 0.948,
      "step": 1400
    },
    {
      "epoch": 1.3051305130513051,
      "grad_norm": 1.3920964002609253,
      "learning_rate": 0.0002804905490549055,
      "loss": 0.9398,
      "step": 1450
    },
    {
      "epoch": 1.3501350135013501,
      "grad_norm": 1.0512006282806396,
      "learning_rate": 0.0002798154815481548,
      "loss": 0.9549,
      "step": 1500
    },
    {
      "epoch": 1.3951395139513951,
      "grad_norm": 1.5624510049819946,
      "learning_rate": 0.0002791404140414041,
      "loss": 0.9389,
      "step": 1550
    },
    {
      "epoch": 1.4401440144014401,
      "grad_norm": 1.419769525527954,
      "learning_rate": 0.00027846534653465344,
      "loss": 0.9742,
      "step": 1600
    },
    {
      "epoch": 1.4851485148514851,
      "grad_norm": 1.339928150177002,
      "learning_rate": 0.00027779027902790276,
      "loss": 0.8996,
      "step": 1650
    },
    {
      "epoch": 1.5301530153015301,
      "grad_norm": 1.581011414527893,
      "learning_rate": 0.0002771152115211521,
      "loss": 0.9448,
      "step": 1700
    },
    {
      "epoch": 1.5751575157515751,
      "grad_norm": 1.4521082639694214,
      "learning_rate": 0.0002764401440144014,
      "loss": 0.9569,
      "step": 1750
    },
    {
      "epoch": 1.6201620162016201,
      "grad_norm": 1.8866684436798096,
      "learning_rate": 0.0002757650765076507,
      "loss": 0.9262,
      "step": 1800
    },
    {
      "epoch": 1.6651665166516652,
      "grad_norm": 1.196537971496582,
      "learning_rate": 0.0002750900090009001,
      "loss": 0.8732,
      "step": 1850
    },
    {
      "epoch": 1.7101710171017102,
      "grad_norm": 1.562920331954956,
      "learning_rate": 0.0002744149414941494,
      "loss": 0.8948,
      "step": 1900
    },
    {
      "epoch": 1.7551755175517552,
      "grad_norm": 1.6307103633880615,
      "learning_rate": 0.00027373987398739873,
      "loss": 0.9041,
      "step": 1950
    },
    {
      "epoch": 1.8001800180018002,
      "grad_norm": 1.703405737876892,
      "learning_rate": 0.00027306480648064805,
      "loss": 0.902,
      "step": 2000
    },
    {
      "epoch": 1.8451845184518452,
      "grad_norm": 1.2685860395431519,
      "learning_rate": 0.00027238973897389737,
      "loss": 0.9213,
      "step": 2050
    },
    {
      "epoch": 1.8901890189018902,
      "grad_norm": 1.535436749458313,
      "learning_rate": 0.0002717146714671467,
      "loss": 0.9189,
      "step": 2100
    },
    {
      "epoch": 1.9351935193519352,
      "grad_norm": 2.1317989826202393,
      "learning_rate": 0.000271039603960396,
      "loss": 0.9038,
      "step": 2150
    },
    {
      "epoch": 1.9801980198019802,
      "grad_norm": 1.1551074981689453,
      "learning_rate": 0.00027036453645364533,
      "loss": 0.8979,
      "step": 2200
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.9025762677192688,
      "eval_runtime": 24.316,
      "eval_samples_per_second": 81.222,
      "eval_steps_per_second": 10.158,
      "step": 2222
    },
    {
      "epoch": 2.025202520252025,
      "grad_norm": 1.3552322387695312,
      "learning_rate": 0.00026968946894689465,
      "loss": 0.8612,
      "step": 2250
    },
    {
      "epoch": 2.07020702070207,
      "grad_norm": 2.1543712615966797,
      "learning_rate": 0.00026901440144014397,
      "loss": 0.8818,
      "step": 2300
    },
    {
      "epoch": 2.115211521152115,
      "grad_norm": 1.6712708473205566,
      "learning_rate": 0.00026833933393339334,
      "loss": 0.8269,
      "step": 2350
    },
    {
      "epoch": 2.16021602160216,
      "grad_norm": 0.922343909740448,
      "learning_rate": 0.00026766426642664266,
      "loss": 0.8457,
      "step": 2400
    },
    {
      "epoch": 2.205220522052205,
      "grad_norm": 1.226658821105957,
      "learning_rate": 0.000266989198919892,
      "loss": 0.8504,
      "step": 2450
    },
    {
      "epoch": 2.25022502250225,
      "grad_norm": 1.3592647314071655,
      "learning_rate": 0.0002663141314131413,
      "loss": 0.7969,
      "step": 2500
    },
    {
      "epoch": 2.295229522952295,
      "grad_norm": 1.4740206003189087,
      "learning_rate": 0.0002656390639063906,
      "loss": 0.8371,
      "step": 2550
    },
    {
      "epoch": 2.34023402340234,
      "grad_norm": 1.120740294456482,
      "learning_rate": 0.00026496399639963994,
      "loss": 0.804,
      "step": 2600
    },
    {
      "epoch": 2.385238523852385,
      "grad_norm": 1.4228826761245728,
      "learning_rate": 0.00026428892889288926,
      "loss": 0.849,
      "step": 2650
    },
    {
      "epoch": 2.43024302430243,
      "grad_norm": 1.0827924013137817,
      "learning_rate": 0.0002636138613861386,
      "loss": 0.8384,
      "step": 2700
    },
    {
      "epoch": 2.4752475247524752,
      "grad_norm": 2.2025513648986816,
      "learning_rate": 0.0002629387938793879,
      "loss": 0.8334,
      "step": 2750
    },
    {
      "epoch": 2.5202520252025202,
      "grad_norm": 1.1313211917877197,
      "learning_rate": 0.0002622637263726372,
      "loss": 0.8203,
      "step": 2800
    },
    {
      "epoch": 2.5652565256525652,
      "grad_norm": 1.1259087324142456,
      "learning_rate": 0.0002615886588658866,
      "loss": 0.8247,
      "step": 2850
    },
    {
      "epoch": 2.6102610261026102,
      "grad_norm": 1.1311235427856445,
      "learning_rate": 0.0002609135913591359,
      "loss": 0.8352,
      "step": 2900
    },
    {
      "epoch": 2.6552655265526552,
      "grad_norm": 1.8167163133621216,
      "learning_rate": 0.00026023852385238523,
      "loss": 0.7948,
      "step": 2950
    },
    {
      "epoch": 2.7002700270027002,
      "grad_norm": 2.015435218811035,
      "learning_rate": 0.00025956345634563455,
      "loss": 0.8348,
      "step": 3000
    },
    {
      "epoch": 2.7452745274527453,
      "grad_norm": 1.0866929292678833,
      "learning_rate": 0.00025888838883888387,
      "loss": 0.8312,
      "step": 3050
    },
    {
      "epoch": 2.7902790279027903,
      "grad_norm": 1.3565593957901,
      "learning_rate": 0.0002582133213321332,
      "loss": 0.8244,
      "step": 3100
    },
    {
      "epoch": 2.8352835283528353,
      "grad_norm": 1.2676953077316284,
      "learning_rate": 0.0002575382538253825,
      "loss": 0.8429,
      "step": 3150
    },
    {
      "epoch": 2.8802880288028803,
      "grad_norm": 0.990146279335022,
      "learning_rate": 0.0002568631863186318,
      "loss": 0.8553,
      "step": 3200
    },
    {
      "epoch": 2.9252925292529253,
      "grad_norm": 1.5129445791244507,
      "learning_rate": 0.00025618811881188114,
      "loss": 0.845,
      "step": 3250
    },
    {
      "epoch": 2.9702970297029703,
      "grad_norm": 1.3429137468338013,
      "learning_rate": 0.00025551305130513046,
      "loss": 0.8167,
      "step": 3300
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.9065647125244141,
      "eval_runtime": 26.8891,
      "eval_samples_per_second": 73.45,
      "eval_steps_per_second": 9.186,
      "step": 3333
    },
    {
      "epoch": 3.0153015301530153,
      "grad_norm": 1.4645482301712036,
      "learning_rate": 0.00025483798379837984,
      "loss": 0.8373,
      "step": 3350
    },
    {
      "epoch": 3.0603060306030603,
      "grad_norm": 1.0227354764938354,
      "learning_rate": 0.00025416291629162916,
      "loss": 0.7483,
      "step": 3400
    },
    {
      "epoch": 3.1053105310531053,
      "grad_norm": 1.2673429250717163,
      "learning_rate": 0.0002534878487848785,
      "loss": 0.7674,
      "step": 3450
    },
    {
      "epoch": 3.1503150315031503,
      "grad_norm": 0.9181433320045471,
      "learning_rate": 0.0002528127812781278,
      "loss": 0.7322,
      "step": 3500
    },
    {
      "epoch": 3.1953195319531953,
      "grad_norm": 1.2463041543960571,
      "learning_rate": 0.0002521377137713771,
      "loss": 0.7522,
      "step": 3550
    },
    {
      "epoch": 3.2403240324032403,
      "grad_norm": 1.4394763708114624,
      "learning_rate": 0.00025146264626462643,
      "loss": 0.7543,
      "step": 3600
    },
    {
      "epoch": 3.2853285328532853,
      "grad_norm": 1.3698155879974365,
      "learning_rate": 0.00025078757875787575,
      "loss": 0.737,
      "step": 3650
    },
    {
      "epoch": 3.3303330333033303,
      "grad_norm": 1.4233675003051758,
      "learning_rate": 0.0002501125112511251,
      "loss": 0.7588,
      "step": 3700
    },
    {
      "epoch": 3.3753375337533753,
      "grad_norm": 1.1487396955490112,
      "learning_rate": 0.0002494374437443744,
      "loss": 0.7719,
      "step": 3750
    },
    {
      "epoch": 3.4203420342034203,
      "grad_norm": 1.520373821258545,
      "learning_rate": 0.0002487623762376237,
      "loss": 0.7251,
      "step": 3800
    },
    {
      "epoch": 3.4653465346534653,
      "grad_norm": 1.7705901861190796,
      "learning_rate": 0.0002480873087308731,
      "loss": 0.7851,
      "step": 3850
    },
    {
      "epoch": 3.5103510351035103,
      "grad_norm": 1.3161582946777344,
      "learning_rate": 0.0002474122412241224,
      "loss": 0.7748,
      "step": 3900
    },
    {
      "epoch": 3.5553555355535553,
      "grad_norm": 1.208681583404541,
      "learning_rate": 0.0002467371737173717,
      "loss": 0.7716,
      "step": 3950
    },
    {
      "epoch": 3.6003600360036003,
      "grad_norm": 1.465001106262207,
      "learning_rate": 0.00024606210621062104,
      "loss": 0.7771,
      "step": 4000
    },
    {
      "epoch": 3.6453645364536453,
      "grad_norm": 1.8899554014205933,
      "learning_rate": 0.00024538703870387036,
      "loss": 0.8333,
      "step": 4050
    },
    {
      "epoch": 3.6903690369036903,
      "grad_norm": 1.2060937881469727,
      "learning_rate": 0.0002447119711971197,
      "loss": 0.763,
      "step": 4100
    },
    {
      "epoch": 3.7353735373537353,
      "grad_norm": 1.5062161684036255,
      "learning_rate": 0.00024403690369036903,
      "loss": 0.7807,
      "step": 4150
    },
    {
      "epoch": 3.7803780378037803,
      "grad_norm": 1.163336157798767,
      "learning_rate": 0.00024336183618361835,
      "loss": 0.7743,
      "step": 4200
    },
    {
      "epoch": 3.8253825382538253,
      "grad_norm": 1.9314416646957397,
      "learning_rate": 0.00024268676867686767,
      "loss": 0.7521,
      "step": 4250
    },
    {
      "epoch": 3.8703870387038704,
      "grad_norm": 1.3516621589660645,
      "learning_rate": 0.000242011701170117,
      "loss": 0.7761,
      "step": 4300
    },
    {
      "epoch": 3.9153915391539154,
      "grad_norm": 1.1826139688491821,
      "learning_rate": 0.00024133663366336633,
      "loss": 0.7437,
      "step": 4350
    },
    {
      "epoch": 3.9603960396039604,
      "grad_norm": 1.1452081203460693,
      "learning_rate": 0.00024066156615661565,
      "loss": 0.8253,
      "step": 4400
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.9209399223327637,
      "eval_runtime": 26.1549,
      "eval_samples_per_second": 75.512,
      "eval_steps_per_second": 9.444,
      "step": 4444
    },
    {
      "epoch": 4.005400540054006,
      "grad_norm": 1.0654985904693604,
      "learning_rate": 0.00023998649864986497,
      "loss": 0.7773,
      "step": 4450
    },
    {
      "epoch": 4.05040504050405,
      "grad_norm": 1.4444602727890015,
      "learning_rate": 0.0002393114311431143,
      "loss": 0.6745,
      "step": 4500
    },
    {
      "epoch": 4.095409540954096,
      "grad_norm": 1.678156852722168,
      "learning_rate": 0.0002386363636363636,
      "loss": 0.678,
      "step": 4550
    },
    {
      "epoch": 4.14041404140414,
      "grad_norm": 1.513692855834961,
      "learning_rate": 0.00023796129612961296,
      "loss": 0.7418,
      "step": 4600
    },
    {
      "epoch": 4.185418541854186,
      "grad_norm": 1.160365343093872,
      "learning_rate": 0.00023728622862286228,
      "loss": 0.7086,
      "step": 4650
    },
    {
      "epoch": 4.23042304230423,
      "grad_norm": 1.5113712549209595,
      "learning_rate": 0.0002366111611161116,
      "loss": 0.6957,
      "step": 4700
    },
    {
      "epoch": 4.275427542754276,
      "grad_norm": 1.0533863306045532,
      "learning_rate": 0.00023593609360936092,
      "loss": 0.7228,
      "step": 4750
    },
    {
      "epoch": 4.32043204320432,
      "grad_norm": 1.107633113861084,
      "learning_rate": 0.00023526102610261024,
      "loss": 0.719,
      "step": 4800
    },
    {
      "epoch": 4.365436543654366,
      "grad_norm": 1.6609954833984375,
      "learning_rate": 0.00023458595859585958,
      "loss": 0.6635,
      "step": 4850
    },
    {
      "epoch": 4.41044104410441,
      "grad_norm": 1.5400398969650269,
      "learning_rate": 0.0002339108910891089,
      "loss": 0.7432,
      "step": 4900
    },
    {
      "epoch": 4.455445544554456,
      "grad_norm": 1.6639013290405273,
      "learning_rate": 0.00023323582358235822,
      "loss": 0.7327,
      "step": 4950
    },
    {
      "epoch": 4.5004500450045,
      "grad_norm": 1.6096299886703491,
      "learning_rate": 0.00023256075607560754,
      "loss": 0.7091,
      "step": 5000
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 2.230414867401123,
      "learning_rate": 0.00023188568856885686,
      "loss": 0.7244,
      "step": 5050
    },
    {
      "epoch": 4.59045904590459,
      "grad_norm": 1.3407882452011108,
      "learning_rate": 0.0002312106210621062,
      "loss": 0.6922,
      "step": 5100
    },
    {
      "epoch": 4.635463546354636,
      "grad_norm": 1.1129090785980225,
      "learning_rate": 0.00023053555355535553,
      "loss": 0.7072,
      "step": 5150
    },
    {
      "epoch": 4.68046804680468,
      "grad_norm": 1.3547892570495605,
      "learning_rate": 0.00022986048604860485,
      "loss": 0.6343,
      "step": 5200
    },
    {
      "epoch": 4.725472547254725,
      "grad_norm": 1.7015080451965332,
      "learning_rate": 0.00022918541854185416,
      "loss": 0.7388,
      "step": 5250
    },
    {
      "epoch": 4.77047704770477,
      "grad_norm": 1.2887763977050781,
      "learning_rate": 0.00022851035103510348,
      "loss": 0.7265,
      "step": 5300
    },
    {
      "epoch": 4.815481548154816,
      "grad_norm": 1.458093523979187,
      "learning_rate": 0.00022783528352835283,
      "loss": 0.7355,
      "step": 5350
    },
    {
      "epoch": 4.86048604860486,
      "grad_norm": 1.142075538635254,
      "learning_rate": 0.00022716021602160215,
      "loss": 0.7353,
      "step": 5400
    },
    {
      "epoch": 4.905490549054905,
      "grad_norm": 1.1089411973953247,
      "learning_rate": 0.00022648514851485147,
      "loss": 0.7262,
      "step": 5450
    },
    {
      "epoch": 4.9504950495049505,
      "grad_norm": 1.1364948749542236,
      "learning_rate": 0.0002258100810081008,
      "loss": 0.7618,
      "step": 5500
    },
    {
      "epoch": 4.995499549954996,
      "grad_norm": 1.3126716613769531,
      "learning_rate": 0.0002251350135013501,
      "loss": 0.7354,
      "step": 5550
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.9395853877067566,
      "eval_runtime": 25.7076,
      "eval_samples_per_second": 76.825,
      "eval_steps_per_second": 9.608,
      "step": 5555
    }
  ],
  "logging_steps": 50,
  "max_steps": 22220,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 3
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 744993175633920.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
